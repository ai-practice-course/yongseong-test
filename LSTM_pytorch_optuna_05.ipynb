{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGUfT-SBmVTD",
        "outputId": "4ed6d245-c401-4675-8b72-fe600507a456"
      },
      "outputs": [],
      "source": [
        "# !pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4M4OxERWmcnY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import joblib\n",
        "import pickle\n",
        "import optuna\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x-ltCAJmckB",
        "outputId": "320790e5-e722-4846-e38d-1cd1d8dbefa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1858 entries, 0 to 1857\n",
            "Data columns (total 18 columns):\n",
            " #   Column           Non-Null Count  Dtype         \n",
            "---  ------           --------------  -----         \n",
            " 0   Date             1858 non-null   datetime64[ns]\n",
            " 1   Account DOW      1858 non-null   object        \n",
            " 2   REV OBD          1858 non-null   int64         \n",
            " 3   OBD NET+FSC_KRW  1858 non-null   float64       \n",
            " 4   OBD A/R_KRW      1858 non-null   float64       \n",
            " 5   REV CPN          1858 non-null   int64         \n",
            " 6   CPN NET+FSC_KRW  1858 non-null   float64       \n",
            " 7   CPN A/R_KRW      1858 non-null   float64       \n",
            " 8   REV TKT          1858 non-null   int64         \n",
            " 9   TKT NET+FSC_KRW  1858 non-null   float64       \n",
            " 10  TKT A/R_KRW      1858 non-null   float64       \n",
            " 11  WTI              1858 non-null   float64       \n",
            " 12  exchanges        1858 non-null   float64       \n",
            " 13  kospi            1858 non-null   float64       \n",
            " 14  rates            1858 non-null   float64       \n",
            " 15  stock_a          1858 non-null   int64         \n",
            " 16  stock_k          1858 non-null   int64         \n",
            " 17  stock_kkj        1858 non-null   int64         \n",
            "dtypes: datetime64[ns](1), float64(10), int64(6), object(1)\n",
            "memory usage: 261.4+ KB\n"
          ]
        }
      ],
      "source": [
        "data=pd.read_excel('./data_full.xlsx')\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tit7FldnXBk",
        "outputId": "229d313d-d218-4291-93fa-b4331d5698e6"
      },
      "outputs": [],
      "source": [
        "data = data[data[\"Date\"].isin(pd.date_range('2016-01-04', '2019-11-30'))]\n",
        "data.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SytPlWa-mchZ"
      },
      "outputs": [],
      "source": [
        "data = data[['Date', 'REV OBD']]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scale_cols = ['REV OBD']\n",
        "\n",
        "# 예측 데이터 사이즈\n",
        "max_prediction_length = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vM-XXZSAmce6"
      },
      "outputs": [],
      "source": [
        "# 학습용 데이터\n",
        "# 전체 데이터의 70%만 사용\n",
        "data_p = data.iloc[:int(data.index.max() * .7), :]\n",
        "training_data = scaler.fit_transform(data_p[scale_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QFdwc-YmccC",
        "outputId": "276c2460-d5a1-4955-d435-5489f7616412"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(429, 1)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# max_prediction_length 만큼의 데이터는 예측 데이터와 비교를 위해 분리\n",
        "actual_data = data.loc[~data.index.isin(data_p.index)][scale_cols]\n",
        "actual_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ChKBNVnrmcZC"
      },
      "outputs": [],
      "source": [
        "def sliding_windows(data, lookback_length, forecast_length):\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "    \n",
        "    for i in range(lookback_length, len(data) - forecast_length + 1):\n",
        "        _x = data[(i-lookback_length) : i]\n",
        "        _y = data[i : (i + forecast_length)]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "\n",
        "def get_data_loader(X, y, batch_size):\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
        "\n",
        "    train_ds = TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
        "    train_dl = DataLoader(train_ds, batch_size = batch_size)\n",
        "\n",
        "    val_ds = TensorDataset(torch.Tensor(x_val), torch.Tensor(y_val))\n",
        "    val_dl = DataLoader(val_ds, batch_size = batch_size)\n",
        "\n",
        "    input_size = x_train.shape[-1]\n",
        "\n",
        "    return train_dl, val_dl, input_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "x, y = sliding_windows(training_data, 60, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.99363326e-01],\n",
              "       [2.49069919e-01],\n",
              "       [1.78191999e-01],\n",
              "       [3.06830821e-04],\n",
              "       [9.66900625e-02],\n",
              "       [1.93802017e-01],\n",
              "       [2.80289955e-01],\n",
              "       [1.82142446e-01],\n",
              "       [2.58926859e-01],\n",
              "       [1.47854102e-01],\n",
              "       [5.92950562e-02],\n",
              "       [1.29559314e-01],\n",
              "       [1.84865570e-01],\n",
              "       [2.74997123e-01],\n",
              "       [1.75737353e-01],\n",
              "       [2.49300042e-01],\n",
              "       [1.48697887e-01],\n",
              "       [6.52015495e-04],\n",
              "       [7.51735512e-02],\n",
              "       [1.62006674e-01],\n",
              "       [2.46346796e-01],\n",
              "       [1.53261995e-01],\n",
              "       [2.19384037e-01],\n",
              "       [1.82410923e-01],\n",
              "       [1.91769263e-02],\n",
              "       [1.19970851e-01],\n",
              "       [1.97407280e-01],\n",
              "       [2.68707092e-01],\n",
              "       [1.44018717e-01],\n",
              "       [2.81977525e-01],\n",
              "       [1.22118667e-01],\n",
              "       [8.22306601e-02],\n",
              "       [1.51766195e-01],\n",
              "       [2.73194492e-01],\n",
              "       [3.58915353e-01],\n",
              "       [2.89226403e-01],\n",
              "       [4.07087792e-01],\n",
              "       [2.35569363e-01],\n",
              "       [1.57365857e-01],\n",
              "       [3.63709585e-01],\n",
              "       [1.96947033e-01],\n",
              "       [3.48866644e-01],\n",
              "       [2.56165382e-01],\n",
              "       [4.22544395e-01],\n",
              "       [2.38714379e-01],\n",
              "       [9.40436467e-02],\n",
              "       [2.20803130e-01],\n",
              "       [2.66866107e-01],\n",
              "       [3.67161431e-01],\n",
              "       [2.32961301e-01],\n",
              "       [4.01219653e-01],\n",
              "       [2.11022897e-01],\n",
              "       [7.34092740e-02],\n",
              "       [1.78844015e-01],\n",
              "       [2.01741265e-01],\n",
              "       [3.29076056e-01],\n",
              "       [2.77873662e-01],\n",
              "       [2.20764776e-01],\n",
              "       [0.00000000e+00],\n",
              "       [3.87757450e-02],\n",
              "       [3.46565412e-01],\n",
              "       [3.94891267e-01],\n",
              "       [1.93150002e-01],\n",
              "       [2.64181337e-01],\n",
              "       [5.31200859e-01],\n",
              "       [2.34457101e-01],\n",
              "       [4.01564837e-02],\n",
              "       [1.27564914e-01],\n",
              "       [2.35722778e-01],\n",
              "       [3.86415065e-01],\n",
              "       [2.48648027e-01],\n",
              "       [3.21712116e-01],\n",
              "       [2.55091474e-01],\n",
              "       [8.65646454e-02],\n",
              "       [1.82909523e-01],\n",
              "       [2.61765044e-01],\n",
              "       [3.89099835e-01],\n",
              "       [2.97242358e-01],\n",
              "       [3.64093123e-01],\n",
              "       [2.35032409e-01],\n",
              "       [1.06662064e-01],\n",
              "       [1.60088981e-01],\n",
              "       [2.60576075e-01],\n",
              "       [4.29256319e-01],\n",
              "       [3.02420128e-01],\n",
              "       [3.17876731e-01],\n",
              "       [2.09373682e-01],\n",
              "       [9.84543397e-02],\n",
              "       [1.61738197e-01],\n",
              "       [3.58224984e-01],\n",
              "       [5.84282591e-01],\n",
              "       [5.54289878e-01],\n",
              "       [4.06320715e-01],\n",
              "       [5.10106240e-01],\n",
              "       [2.85966325e-01],\n",
              "       [1.69293906e-01],\n",
              "       [2.69090630e-01],\n",
              "       [3.19832777e-01],\n",
              "       [2.84355464e-01],\n",
              "       [3.23668162e-01],\n",
              "       [2.35761132e-01],\n",
              "       [8.29977371e-02],\n",
              "       [1.81183600e-01],\n",
              "       [3.01729759e-01],\n",
              "       [3.83039926e-01],\n",
              "       [3.23783224e-01],\n",
              "       [3.62252138e-01],\n",
              "       [2.89686649e-01],\n",
              "       [1.59590381e-01],\n",
              "       [2.30851839e-01],\n",
              "       [3.60334446e-01],\n",
              "       [4.53994554e-01],\n",
              "       [4.58865493e-01],\n",
              "       [4.47436045e-01],\n",
              "       [3.79741495e-01],\n",
              "       [2.50757489e-01],\n",
              "       [3.11816822e-01],\n",
              "       [4.14566793e-01],\n",
              "       [4.04019484e-01],\n",
              "       [3.48751582e-01],\n",
              "       [3.06217160e-01],\n",
              "       [2.37908948e-01],\n",
              "       [8.82138611e-02],\n",
              "       [1.76772907e-01],\n",
              "       [2.47727534e-01],\n",
              "       [3.50017259e-01],\n",
              "       [3.51282936e-01],\n",
              "       [3.41732827e-01],\n",
              "       [2.39136271e-01],\n",
              "       [1.08541403e-01],\n",
              "       [2.28013654e-01],\n",
              "       [3.12852376e-01],\n",
              "       [4.10961531e-01],\n",
              "       [3.92973574e-01],\n",
              "       [3.36286580e-01],\n",
              "       [2.56702336e-01],\n",
              "       [2.09296974e-01],\n",
              "       [3.85532927e-01],\n",
              "       [4.97833007e-01],\n",
              "       [4.43830783e-01],\n",
              "       [5.21919227e-01],\n",
              "       [4.66076017e-01],\n",
              "       [3.57956507e-01],\n",
              "       [2.84892417e-01],\n",
              "       [4.68415602e-01],\n",
              "       [4.99673992e-01],\n",
              "       [6.97963410e-01],\n",
              "       [8.04740536e-01],\n",
              "       [7.06516320e-01],\n",
              "       [5.34460937e-01],\n",
              "       [4.47244276e-01],\n",
              "       [6.16883366e-01],\n",
              "       [5.41402984e-01],\n",
              "       [5.53944694e-01],\n",
              "       [6.63406589e-01],\n",
              "       [5.94331301e-01],\n",
              "       [3.74985617e-01],\n",
              "       [2.16929391e-01],\n",
              "       [3.63671231e-01],\n",
              "       [4.09542439e-01],\n",
              "       [5.29820120e-01],\n",
              "       [5.89767192e-01],\n",
              "       [5.23261612e-01],\n",
              "       [5.19771411e-01],\n",
              "       [3.29996548e-01],\n",
              "       [2.93483680e-01],\n",
              "       [3.42538258e-01],\n",
              "       [3.63249338e-01],\n",
              "       [4.26916734e-01],\n",
              "       [3.89751851e-01],\n",
              "       [3.08058144e-01],\n",
              "       [2.36873394e-01],\n",
              "       [2.47574119e-01],\n",
              "       [3.27618609e-01],\n",
              "       [4.18977486e-01],\n",
              "       [4.01296360e-01],\n",
              "       [3.66547770e-01],\n",
              "       [2.12096805e-01],\n",
              "       [9.24711387e-02],\n",
              "       [1.71288306e-01],\n",
              "       [2.46385149e-01],\n",
              "       [2.82437771e-01],\n",
              "       [2.44390749e-01],\n",
              "       [2.53480612e-01],\n",
              "       [1.51919610e-01],\n",
              "       [2.04809573e-02],\n",
              "       [1.53722241e-01],\n",
              "       [2.73731446e-01],\n",
              "       [4.19092548e-01],\n",
              "       [4.77658881e-01],\n",
              "       [2.70969969e-01],\n",
              "       [1.09692019e-01],\n",
              "       [3.67966862e-01],\n",
              "       [6.11015226e-01],\n",
              "       [3.62942508e-01],\n",
              "       [5.09607640e-01],\n",
              "       [5.94676485e-01],\n",
              "       [7.62436237e-01],\n",
              "       [4.55758831e-01],\n",
              "       [1.98634603e-01],\n",
              "       [2.07724466e-01],\n",
              "       [2.15126759e-01],\n",
              "       [3.29076056e-01],\n",
              "       [3.68503816e-01],\n",
              "       [4.30713765e-01],\n",
              "       [3.12046945e-01],\n",
              "       [1.63770951e-01],\n",
              "       [2.84355464e-01],\n",
              "       [4.06435776e-01],\n",
              "       [6.20948874e-01],\n",
              "       [5.40981092e-01],\n",
              "       [3.95965175e-01],\n",
              "       [4.63889848e-01],\n",
              "       [2.69819353e-01],\n",
              "       [1.90388525e-01],\n",
              "       [2.14244621e-01],\n",
              "       [2.85045833e-01],\n",
              "       [2.63107429e-01],\n",
              "       [3.63786292e-01],\n",
              "       [2.22759176e-01],\n",
              "       [1.23192575e-01],\n",
              "       [2.69934415e-01],\n",
              "       [3.30341733e-01],\n",
              "       [4.98254900e-01],\n",
              "       [4.31097304e-01],\n",
              "       [5.21650750e-01],\n",
              "       [3.68465462e-01],\n",
              "       [2.12787174e-01],\n",
              "       [3.29996548e-01],\n",
              "       [4.04863269e-01],\n",
              "       [4.65577417e-01],\n",
              "       [4.60706478e-01],\n",
              "       [5.37107352e-01],\n",
              "       [3.28462394e-01],\n",
              "       [1.98327772e-01],\n",
              "       [2.64756645e-01],\n",
              "       [3.33793580e-01],\n",
              "       [4.77121927e-01],\n",
              "       [3.37974150e-01],\n",
              "       [3.75177387e-01],\n",
              "       [2.71430215e-01],\n",
              "       [1.27833391e-01],\n",
              "       [1.61929966e-01],\n",
              "       [2.58850151e-01],\n",
              "       [3.75560925e-01],\n",
              "       [3.29267825e-01],\n",
              "       [4.17289917e-01],\n",
              "       [2.97625897e-01],\n",
              "       [1.23998006e-01],\n",
              "       [2.08529897e-01],\n",
              "       [2.92870019e-01],\n",
              "       [4.24385380e-01],\n",
              "       [3.72147432e-01],\n",
              "       [3.99800560e-01],\n",
              "       [3.06984237e-01],\n",
              "       [1.60280750e-01],\n",
              "       [2.42357995e-01],\n",
              "       [2.95209604e-01],\n",
              "       [4.49583861e-01],\n",
              "       [4.02370268e-01],\n",
              "       [4.46668968e-01],\n",
              "       [3.44686074e-01],\n",
              "       [1.36961608e-01],\n",
              "       [2.36873394e-01],\n",
              "       [3.03494036e-01],\n",
              "       [4.31174011e-01],\n",
              "       [3.76443064e-01],\n",
              "       [4.75549419e-01],\n",
              "       [3.32374487e-01],\n",
              "       [1.29137422e-01],\n",
              "       [2.40862195e-01],\n",
              "       [3.05641852e-01],\n",
              "       [4.20358225e-01],\n",
              "       [3.52395198e-01],\n",
              "       [4.24116903e-01],\n",
              "       [3.17723315e-01],\n",
              "       [1.52993518e-01],\n",
              "       [2.16584206e-01],\n",
              "       [3.01001036e-01],\n",
              "       [4.01641545e-01],\n",
              "       [4.04518084e-01],\n",
              "       [4.99290454e-01],\n",
              "       [3.05181605e-01],\n",
              "       [2.32846239e-01],\n",
              "       [3.34982549e-01],\n",
              "       [4.43217121e-01],\n",
              "       [4.90584129e-01],\n",
              "       [4.39841982e-01],\n",
              "       [4.78157481e-01],\n",
              "       [3.43382043e-01],\n",
              "       [2.07571051e-01],\n",
              "       [2.44850995e-01],\n",
              "       [2.46500211e-01],\n",
              "       [3.32796379e-01],\n",
              "       [2.75687493e-01],\n",
              "       [1.47547271e-01],\n",
              "       [1.96410079e-01],\n",
              "       [1.33739884e-01],\n",
              "       [2.13592605e-01],\n",
              "       [2.22644115e-01],\n",
              "       [2.61765044e-01],\n",
              "       [2.49760288e-01],\n",
              "       [1.61814904e-01],\n",
              "       [1.40298393e-01],\n",
              "       [1.29520960e-01],\n",
              "       [2.20036053e-01],\n",
              "       [2.59310398e-01],\n",
              "       [3.51589767e-01],\n",
              "       [3.69999616e-01],\n",
              "       [5.38488091e-01],\n",
              "       [4.80918958e-01],\n",
              "       [4.41452844e-01],\n",
              "       [4.73516665e-01],\n",
              "       [5.21267211e-01],\n",
              "       [5.98205040e-01],\n",
              "       [5.27365474e-01],\n",
              "       [6.44651555e-01],\n",
              "       [5.24105396e-01],\n",
              "       [3.94047482e-01],\n",
              "       [4.58597016e-01],\n",
              "       [4.77236988e-01],\n",
              "       [5.62420895e-01],\n",
              "       [4.66689679e-01],\n",
              "       [4.15909178e-01],\n",
              "       [2.74076631e-01],\n",
              "       [2.35224178e-01],\n",
              "       [4.47666168e-01],\n",
              "       [4.91389560e-01],\n",
              "       [4.40992598e-01],\n",
              "       [4.28796073e-02],\n",
              "       [3.92513328e-01],\n",
              "       [5.79373298e-01],\n",
              "       [3.96540482e-01],\n",
              "       [3.34100410e-01],\n",
              "       [2.17811529e-01],\n",
              "       [3.07099298e-01],\n",
              "       [2.65945614e-01],\n",
              "       [3.66777893e-01],\n",
              "       [2.86004679e-01],\n",
              "       [2.28972500e-01],\n",
              "       [3.06754113e-01],\n",
              "       [3.70728340e-01],\n",
              "       [4.92156637e-01],\n",
              "       [4.90699191e-01],\n",
              "       [5.80102021e-01],\n",
              "       [4.85674836e-01],\n",
              "       [4.47014153e-01],\n",
              "       [5.52103709e-01],\n",
              "       [5.70206727e-01],\n",
              "       [6.65861236e-01],\n",
              "       [6.30192153e-01],\n",
              "       [6.73301883e-01],\n",
              "       [5.63839988e-01],\n",
              "       [5.00441069e-01],\n",
              "       [5.40137307e-01],\n",
              "       [6.05377210e-01],\n",
              "       [6.53741418e-01],\n",
              "       [6.52092203e-01],\n",
              "       [5.85011314e-01],\n",
              "       [4.07471330e-01],\n",
              "       [4.09389023e-01],\n",
              "       [6.16576535e-01],\n",
              "       [1.96908679e-01],\n",
              "       [2.80750201e-01],\n",
              "       [3.23361332e-01],\n",
              "       [3.93625590e-01],\n",
              "       [2.99581943e-01],\n",
              "       [8.72166609e-02],\n",
              "       [2.01357726e-01],\n",
              "       [2.47574119e-01],\n",
              "       [3.75791048e-01],\n",
              "       [2.26095961e-01],\n",
              "       [3.62712384e-01],\n",
              "       [2.08223066e-01],\n",
              "       [1.08541403e-01],\n",
              "       [1.88931078e-01],\n",
              "       [2.77605185e-01],\n",
              "       [3.22402485e-01],\n",
              "       [2.46461857e-01],\n",
              "       [3.24780424e-01],\n",
              "       [2.25213823e-01],\n",
              "       [1.09346834e-01],\n",
              "       [1.41564070e-01],\n",
              "       [2.03927435e-01],\n",
              "       [3.38587811e-01],\n",
              "       [2.47574119e-01],\n",
              "       [3.32566256e-01],\n",
              "       [1.91270663e-01],\n",
              "       [7.33325663e-02],\n",
              "       [1.33164576e-01],\n",
              "       [2.00552295e-01],\n",
              "       [3.11548345e-01],\n",
              "       [2.26249377e-01],\n",
              "       [2.65562076e-01],\n",
              "       [1.23384344e-01],\n",
              "       [3.24857132e-02],\n",
              "       [1.47163733e-01],\n",
              "       [2.31312085e-01],\n",
              "       [3.29267825e-01],\n",
              "       [2.02278219e-01],\n",
              "       [3.35519503e-01],\n",
              "       [1.86591493e-01],\n",
              "       [9.32765696e-02],\n",
              "       [2.02930234e-01],\n",
              "       [2.49530165e-01],\n",
              "       [3.14348176e-01],\n",
              "       [2.05154758e-01],\n",
              "       [3.33755226e-01],\n",
              "       [2.03850727e-01],\n",
              "       [1.35887700e-01],\n",
              "       [2.45196180e-01],\n",
              "       [3.16342577e-01],\n",
              "       [4.32899935e-01],\n",
              "       [3.25087255e-01],\n",
              "       [4.76584973e-01],\n",
              "       [2.85352664e-01],\n",
              "       [2.00322172e-01],\n",
              "       [3.35941395e-01],\n",
              "       [4.76163081e-01],\n",
              "       [6.80320638e-01],\n",
              "       [5.43704215e-01],\n",
              "       [3.47907797e-01],\n",
              "       [2.15050052e-01],\n",
              "       [2.80213247e-01],\n",
              "       [6.06451118e-01],\n",
              "       [3.60219384e-01],\n",
              "       [5.16204503e-01],\n",
              "       [4.81532620e-01],\n",
              "       [6.57576804e-01],\n",
              "       [2.87040233e-01],\n",
              "       [2.05960189e-01],\n",
              "       [1.63195643e-01],\n",
              "       [1.17938097e-01],\n",
              "       [2.84432171e-01],\n",
              "       [1.79764507e-01],\n",
              "       [3.09860776e-01],\n",
              "       [2.13477544e-01],\n",
              "       [1.10497449e-01],\n",
              "       [1.72592337e-01],\n",
              "       [2.41015610e-01],\n",
              "       [3.88217696e-01],\n",
              "       [2.67824953e-01],\n",
              "       [3.39700073e-01],\n",
              "       [2.42626472e-01],\n",
              "       [6.54700265e-02],\n",
              "       [1.55333103e-01],\n",
              "       [2.89533234e-01],\n",
              "       [3.54619722e-01],\n",
              "       [2.37947302e-01],\n",
              "       [2.65485368e-01],\n",
              "       [1.75046983e-01],\n",
              "       [4.34932689e-02],\n",
              "       [1.16749127e-01],\n",
              "       [3.03877575e-01],\n",
              "       [4.48816784e-01],\n",
              "       [4.18900779e-01],\n",
              "       [2.71353507e-01],\n",
              "       [2.78410616e-01],\n",
              "       [4.45633414e-01],\n",
              "       [2.24254976e-01],\n",
              "       [2.31043608e-01],\n",
              "       [3.67544970e-01],\n",
              "       [3.14616653e-01],\n",
              "       [3.39930196e-01],\n",
              "       [2.45426303e-01],\n",
              "       [1.16403943e-01],\n",
              "       [2.22490699e-01],\n",
              "       [3.19564300e-01],\n",
              "       [4.10693054e-01],\n",
              "       [2.61381506e-01],\n",
              "       [3.45836689e-01],\n",
              "       [2.54938059e-01],\n",
              "       [7.73980746e-02],\n",
              "       [2.17849883e-01],\n",
              "       [3.25777624e-01],\n",
              "       [4.94496222e-01],\n",
              "       [3.56153876e-01],\n",
              "       [4.18862425e-01],\n",
              "       [3.40812335e-01],\n",
              "       [1.86859970e-01],\n",
              "       [3.03532390e-01],\n",
              "       [3.69769493e-01],\n",
              "       [4.99635638e-01],\n",
              "       [3.06984237e-01],\n",
              "       [2.90722203e-01],\n",
              "       [2.30545008e-01],\n",
              "       [9.01699076e-02],\n",
              "       [1.94569094e-01],\n",
              "       [1.97637403e-01],\n",
              "       [3.38050857e-01],\n",
              "       [2.83588386e-01],\n",
              "       [2.59195336e-01],\n",
              "       [1.86016185e-01],\n",
              "       [1.01637710e-01],\n",
              "       [1.70291106e-01],\n",
              "       [2.55283243e-01],\n",
              "       [4.31941088e-01],\n",
              "       [3.18145208e-01],\n",
              "       [2.73309554e-01],\n",
              "       [2.13209067e-01],\n",
              "       [1.09078357e-01],\n",
              "       [2.26441146e-01],\n",
              "       [3.82694742e-01],\n",
              "       [4.47819583e-01],\n",
              "       [3.97269206e-01],\n",
              "       [3.67890155e-01],\n",
              "       [3.03455682e-01],\n",
              "       [2.52099873e-01],\n",
              "       [3.59529015e-01],\n",
              "       [4.72864649e-01],\n",
              "       [6.39013539e-01],\n",
              "       [7.41648449e-01],\n",
              "       [6.10593334e-01],\n",
              "       [4.49775630e-01],\n",
              "       [4.42181567e-01],\n",
              "       [5.98396809e-01],\n",
              "       [5.23184904e-01],\n",
              "       [6.00467917e-01],\n",
              "       [6.17612089e-01],\n",
              "       [6.13316458e-01],\n",
              "       [3.37705673e-01],\n",
              "       [2.27706823e-01],\n",
              "       [3.13542745e-01],\n",
              "       [3.76481418e-01],\n",
              "       [5.42975492e-01],\n",
              "       [5.57434894e-01],\n",
              "       [4.02025083e-01],\n",
              "       [4.17558394e-01],\n",
              "       [4.41606259e-01],\n",
              "       [4.06320715e-01],\n",
              "       [2.94672650e-01],\n",
              "       [3.98343114e-01],\n",
              "       [4.42986998e-01],\n",
              "       [4.32056150e-01],\n",
              "       [3.26659763e-01],\n",
              "       [1.50423810e-01],\n",
              "       [2.33996855e-01],\n",
              "       [2.80711848e-01],\n",
              "       [4.17021440e-01],\n",
              "       [3.41617766e-01],\n",
              "       [3.30725271e-01],\n",
              "       [2.04349327e-01],\n",
              "       [6.71959498e-02],\n",
              "       [1.44824148e-01],\n",
              "       [2.18847083e-01],\n",
              "       [4.37694166e-01],\n",
              "       [3.08480037e-01],\n",
              "       [3.21443639e-01],\n",
              "       [2.41514210e-01],\n",
              "       [1.56522073e-01],\n",
              "       [2.64104629e-01],\n",
              "       [3.37513903e-01],\n",
              "       [4.69221033e-01],\n",
              "       [3.76097879e-01],\n",
              "       [4.73555019e-01],\n",
              "       [3.20523147e-01],\n",
              "       [1.82372569e-01],\n",
              "       [2.73769800e-01],\n",
              "       [3.56614122e-01],\n",
              "       [5.99624132e-01],\n",
              "       [4.16599547e-01],\n",
              "       [4.51539907e-01],\n",
              "       [3.64860200e-01],\n",
              "       [1.43021517e-01],\n",
              "       [2.83741802e-01],\n",
              "       [3.84842557e-01],\n",
              "       [5.23261612e-01],\n",
              "       [4.26264718e-01],\n",
              "       [4.34702566e-01],\n",
              "       [3.17531546e-01],\n",
              "       [2.16660914e-01],\n",
              "       [4.00682699e-01],\n",
              "       [5.89460361e-01],\n",
              "       [7.17255398e-01],\n",
              "       [7.33785909e-01],\n",
              "       [6.24822613e-01],\n",
              "       [5.54865186e-01],\n",
              "       [6.74184022e-01],\n",
              "       [6.86879147e-01],\n",
              "       [1.00000000e+00],\n",
              "       [8.53373221e-01],\n",
              "       [7.01491965e-01],\n",
              "       [8.25336555e-01],\n",
              "       [6.59149312e-01],\n",
              "       [5.01246500e-01],\n",
              "       [3.24780424e-01],\n",
              "       [2.24791930e-01],\n",
              "       [2.69512523e-01],\n",
              "       [2.48302842e-01],\n",
              "       [3.83116634e-01],\n",
              "       [2.78065432e-01],\n",
              "       [9.43504775e-02],\n",
              "       [2.16967744e-01],\n",
              "       [2.77835309e-01],\n",
              "       [3.99186898e-01],\n",
              "       [2.83204848e-01],\n",
              "       [4.18632302e-01],\n",
              "       [2.93061788e-01],\n",
              "       [1.04629310e-01],\n",
              "       [2.60000767e-01],\n",
              "       [3.34445595e-01],\n",
              "       [4.63161125e-01],\n",
              "       [3.36286580e-01],\n",
              "       [4.79116327e-01],\n",
              "       [3.40428796e-01],\n",
              "       [1.60779350e-01],\n",
              "       [3.12622253e-01],\n",
              "       [3.45759982e-01],\n",
              "       [5.16779811e-01],\n",
              "       [4.13953132e-01],\n",
              "       [5.00441069e-01],\n",
              "       [4.51654969e-01],\n",
              "       [2.17159514e-01],\n",
              "       [2.92333065e-01],\n",
              "       [3.80777049e-01],\n",
              "       [5.60810033e-01],\n",
              "       [4.87899359e-01],\n",
              "       [5.56169217e-01],\n",
              "       [4.80382004e-01],\n",
              "       [2.39519810e-01],\n",
              "       [3.58685230e-01],\n",
              "       [4.30982242e-01],\n",
              "       [5.66064511e-01],\n",
              "       [4.76584973e-01],\n",
              "       [5.39446937e-01],\n",
              "       [4.32362981e-01],\n",
              "       [1.79150846e-01],\n",
              "       [3.38396042e-01],\n",
              "       [3.57419553e-01],\n",
              "       [4.72711234e-01],\n",
              "       [4.05668699e-01],\n",
              "       [6.15732750e-01],\n",
              "       [4.49967399e-01],\n",
              "       [2.18233422e-01],\n",
              "       [2.60115829e-01],\n",
              "       [4.51194723e-01],\n",
              "       [4.56104016e-01],\n",
              "       [3.73374755e-01],\n",
              "       [4.73286542e-01],\n",
              "       [3.87604035e-01],\n",
              "       [1.96601849e-01],\n",
              "       [2.53135427e-01],\n",
              "       [3.36248226e-01],\n",
              "       [4.80765543e-01],\n",
              "       [3.46603766e-01],\n",
              "       [4.90315652e-01],\n",
              "       [3.74908910e-01],\n",
              "       [2.11406436e-01],\n",
              "       [3.10627853e-01],\n",
              "       [4.02101791e-01],\n",
              "       [4.91619683e-01],\n",
              "       [3.83730296e-01],\n",
              "       [5.01131439e-01],\n",
              "       [3.54274537e-01],\n",
              "       [2.20266176e-01],\n",
              "       [3.36938595e-01],\n",
              "       [4.05476930e-01],\n",
              "       [5.40520845e-01],\n",
              "       [4.29678211e-01],\n",
              "       [3.06102098e-01],\n",
              "       [4.09619146e-01],\n",
              "       [2.71200092e-01],\n",
              "       [1.25838991e-01],\n",
              "       [2.06113604e-01],\n",
              "       [3.19410885e-01],\n",
              "       [3.89176543e-01],\n",
              "       [1.93150002e-01],\n",
              "       [2.24868638e-01],\n",
              "       [1.73589537e-01],\n",
              "       [1.88317416e-01],\n",
              "       [1.26222529e-01],\n",
              "       [2.51716335e-01],\n",
              "       [2.72772600e-01],\n",
              "       [3.95121390e-01],\n",
              "       [3.86606835e-01],\n",
              "       [2.75802554e-01],\n",
              "       [4.55912246e-01],\n",
              "       [4.76661681e-01],\n",
              "       [6.23902121e-01],\n",
              "       [5.75921451e-01],\n",
              "       [6.87837993e-01],\n",
              "       [6.20258505e-01],\n",
              "       [4.90699191e-01],\n",
              "       [5.59659418e-01],\n",
              "       [6.17228551e-01],\n",
              "       [7.20323707e-01],\n",
              "       [6.71921144e-01],\n",
              "       [7.14263798e-01],\n",
              "       [6.20066736e-01],\n",
              "       [5.25792966e-01],\n",
              "       [6.00391209e-01],\n",
              "       [5.95635332e-01],\n",
              "       [7.33440724e-01],\n",
              "       [6.55428988e-01],\n",
              "       [6.83542362e-01],\n",
              "       [5.82556668e-01],\n",
              "       [3.89560081e-01],\n",
              "       [4.66612971e-01],\n",
              "       [4.27990642e-01],\n",
              "       [4.93767499e-01],\n",
              "       [3.91516128e-01],\n",
              "       [4.43370537e-01],\n",
              "       [3.40467150e-01],\n",
              "       [1.41065470e-01],\n",
              "       [2.03697311e-01],\n",
              "       [2.68707092e-01],\n",
              "       [4.15103747e-01],\n",
              "       [3.75139033e-01],\n",
              "       [2.54132628e-01],\n",
              "       [1.05281326e-01],\n",
              "       [2.46922103e-01],\n",
              "       [4.82759943e-01],\n",
              "       [3.33064856e-01],\n",
              "       [1.21543359e-01],\n",
              "       [3.84497373e-01],\n",
              "       [7.24159092e-01],\n",
              "       [4.64848694e-01],\n",
              "       [2.58773444e-01],\n",
              "       [3.15076899e-01],\n",
              "       [2.96436927e-01],\n",
              "       [4.38959844e-01],\n",
              "       [4.30943888e-01],\n",
              "       [5.32888429e-01],\n",
              "       [4.04403022e-01],\n",
              "       [3.56345645e-01],\n",
              "       [6.61258773e-01],\n",
              "       [5.73581866e-01],\n",
              "       [4.09925977e-01],\n",
              "       [4.38883136e-01],\n",
              "       [6.65861236e-01],\n",
              "       [4.83565374e-01],\n",
              "       [2.71468569e-01],\n",
              "       [3.16917884e-01],\n",
              "       [3.93702297e-01],\n",
              "       [5.08687148e-01],\n",
              "       [3.77938864e-01],\n",
              "       [4.79653281e-01],\n",
              "       [3.92398266e-01],\n",
              "       [1.93341771e-01],\n",
              "       [2.98086143e-01],\n",
              "       [3.64246539e-01],\n",
              "       [5.12791010e-01],\n",
              "       [3.69079124e-01],\n",
              "       [4.68032064e-01],\n",
              "       [3.81889311e-01],\n",
              "       [2.25904192e-01],\n",
              "       [2.44659226e-01],\n",
              "       [3.44686074e-01],\n",
              "       [4.52115215e-01],\n",
              "       [3.32029302e-01],\n",
              "       [4.09734208e-01],\n",
              "       [2.85429371e-01],\n",
              "       [1.26797837e-01],\n",
              "       [2.04541096e-01],\n",
              "       [2.51025966e-01],\n",
              "       [3.30648564e-01],\n",
              "       [1.90043340e-01],\n",
              "       [2.73347908e-01],\n",
              "       [2.38215779e-01],\n",
              "       [5.44624708e-02],\n",
              "       [1.90388525e-01],\n",
              "       [3.16112453e-01],\n",
              "       [3.46258582e-01],\n",
              "       [2.53710735e-01],\n",
              "       [4.25075749e-01],\n",
              "       [3.46450351e-01],\n",
              "       [1.84405324e-01],\n",
              "       [3.28270625e-01],\n",
              "       [4.05591992e-01],\n",
              "       [5.10758256e-01],\n",
              "       [4.08545238e-01],\n",
              "       [5.45084954e-01],\n",
              "       [4.52422046e-01],\n",
              "       [2.17734821e-01],\n",
              "       [3.81160588e-01],\n",
              "       [4.85713190e-01],\n",
              "       [6.12165842e-01],\n",
              "       [4.64043263e-01],\n",
              "       [6.34832969e-01],\n",
              "       [4.97986423e-01],\n",
              "       [2.69052276e-01],\n",
              "       [3.81735895e-01],\n",
              "       [5.19426226e-01],\n",
              "       [6.39473785e-01],\n",
              "       [4.30023396e-01],\n",
              "       [3.89214897e-01],\n",
              "       [2.60000767e-01],\n",
              "       [2.52675181e-01],\n",
              "       [1.28178576e-01],\n",
              "       [3.21213516e-01],\n",
              "       [5.17777011e-01],\n",
              "       [3.47716028e-01],\n",
              "       [3.88908066e-01],\n",
              "       [5.83093622e-01],\n",
              "       [2.94749358e-01],\n",
              "       [2.60614429e-01],\n",
              "       [3.33640164e-01],\n",
              "       [4.69297741e-01],\n",
              "       [3.55923753e-01],\n",
              "       [5.01898516e-01],\n",
              "       [4.15755763e-01],\n",
              "       [2.14934990e-01],\n",
              "       [3.26276224e-01],\n",
              "       [5.54021401e-01],\n",
              "       [6.89410501e-01],\n",
              "       [6.07755149e-01],\n",
              "       [4.61051663e-01],\n",
              "       [4.73363249e-01],\n",
              "       [5.07651594e-01],\n",
              "       [3.43420397e-01],\n",
              "       [3.45683274e-01],\n",
              "       [4.80305297e-01],\n",
              "       [3.62482261e-01],\n",
              "       [4.49277030e-01],\n",
              "       [4.00030683e-01],\n",
              "       [1.56100180e-01],\n",
              "       [2.42127872e-01],\n",
              "       [3.84880911e-01],\n",
              "       [6.22444675e-01],\n",
              "       [4.43523952e-01],\n",
              "       [4.01066237e-01],\n",
              "       [3.57994861e-01],\n",
              "       [3.55079968e-01],\n",
              "       [5.77685729e-01],\n",
              "       [2.98814866e-01],\n",
              "       [5.11640394e-01],\n",
              "       [5.77877498e-01],\n",
              "       [4.88129483e-01],\n",
              "       [3.27273425e-01],\n",
              "       [2.59617229e-01],\n",
              "       [5.06769455e-01],\n",
              "       [2.98584743e-01],\n",
              "       [4.16024240e-01],\n",
              "       [4.51693323e-01],\n",
              "       [4.81570974e-01],\n",
              "       [3.42614966e-01],\n",
              "       [1.37115023e-01],\n",
              "       [2.80865263e-01],\n",
              "       [3.48099567e-01],\n",
              "       [5.53791278e-01],\n",
              "       [4.63314540e-01],\n",
              "       [4.85521421e-01],\n",
              "       [4.40378936e-01],\n",
              "       [2.28512254e-01],\n",
              "       [4.00452575e-01],\n",
              "       [4.26609903e-01],\n",
              "       [5.98933763e-01],\n",
              "       [4.93767499e-01],\n",
              "       [3.59989261e-01],\n",
              "       [2.99735358e-01],\n",
              "       [9.20492463e-02],\n",
              "       [2.77106585e-01],\n",
              "       [2.62954014e-01],\n",
              "       [3.98266406e-01],\n",
              "       [3.20561500e-01],\n",
              "       [3.22249070e-01],\n",
              "       [2.64564876e-01],\n",
              "       [1.01484294e-01],\n",
              "       [2.12020097e-01],\n",
              "       [2.85621141e-01],\n",
              "       [4.63928202e-01],\n",
              "       [3.92398266e-01],\n",
              "       [3.45184674e-01],\n",
              "       [2.79331109e-01],\n",
              "       [1.38380700e-01],\n",
              "       [3.07866375e-01],\n",
              "       [3.91170943e-01],\n",
              "       [5.38411383e-01],\n",
              "       [4.52690523e-01],\n",
              "       [3.50669275e-01],\n",
              "       [3.29996548e-01],\n",
              "       [1.93495187e-01],\n",
              "       [4.01142945e-01],\n",
              "       [4.85598128e-01],\n",
              "       [6.84961454e-01],\n",
              "       [7.01146780e-01],\n",
              "       [6.34372723e-01],\n",
              "       [4.86518621e-01],\n",
              "       [4.34779274e-01],\n",
              "       [7.28799908e-01],\n",
              "       [6.95125225e-01],\n",
              "       [6.68699421e-01],\n",
              "       [7.88823687e-01],\n",
              "       [7.47286465e-01],\n",
              "       [5.16856518e-01],\n",
              "       [3.09707360e-01],\n",
              "       [3.71648832e-01],\n",
              "       [4.16062593e-01],\n",
              "       [5.55402140e-01],\n",
              "       [5.62037357e-01],\n",
              "       [4.23925133e-01],\n",
              "       [2.70548077e-01],\n",
              "       [3.57266137e-01],\n",
              "       [5.15053887e-01],\n",
              "       [3.38204273e-01],\n",
              "       [3.72032371e-01],\n",
              "       [5.05081885e-01],\n",
              "       [4.54493154e-01],\n",
              "       [3.53929352e-01],\n",
              "       [1.82525985e-01],\n",
              "       [2.74805354e-01],\n",
              "       [2.62186937e-01],\n",
              "       [4.26763318e-01],\n",
              "       [4.54339738e-01],\n",
              "       [3.54274537e-01],\n",
              "       [3.28347332e-01],\n",
              "       [1.47470563e-01],\n",
              "       [2.34495455e-01],\n",
              "       [3.08556745e-01],\n",
              "       [4.17289917e-01],\n",
              "       [4.38269474e-01],\n",
              "       [3.75714341e-01],\n",
              "       [2.97050589e-01],\n",
              "       [1.91769263e-01],\n",
              "       [3.14616653e-01],\n",
              "       [3.33103210e-01],\n",
              "       [4.66344494e-01],\n",
              "       [4.00222452e-01],\n",
              "       [3.79664787e-01],\n",
              "       [3.04376175e-01],\n",
              "       [1.40106624e-01],\n",
              "       [2.13861082e-01],\n",
              "       [2.89725003e-01],\n",
              "       [5.05312009e-01],\n",
              "       [3.44455951e-01],\n",
              "       [3.00809266e-01],\n",
              "       [2.60729490e-01],\n",
              "       [1.22693975e-01],\n",
              "       [3.03877575e-01]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[:,1,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "C9eplEkh3hvw"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size,\n",
        "                            num_layers = num_layers, batch_first = True)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size  * num_layers, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size, device = x.device))\n",
        "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size, device = x.device))\n",
        "        \n",
        "        # Propagate input through LSTM\n",
        "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
        "        h_out = h_out.view(-1, self.hidden_size * self.num_layers)\n",
        "        # print(f'num_layer = {self.num_layers}, hidden_size = {self.hidden_size}, h_out shape = {h_out.shape}')\n",
        "        out = self.fc(h_out)\n",
        "        # print('output shape = ', len(out))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3_IBkQhZ4CpP"
      },
      "outputs": [],
      "source": [
        "def train(log_interval, model, train_dl, val_dl, optimizer, criterion, epoch):\n",
        "\n",
        "    best_loss = np.inf\n",
        "    for epoch in range(epoch):\n",
        "        train_loss = 0.0\n",
        "        model.train()\n",
        "        for data, target in train_dl:\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "                model = model.cuda()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target) # mean-squared error for regression\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # validation\n",
        "        valid_loss = 0.0\n",
        "        model.eval()\n",
        "        for data, target in val_dl:\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "\n",
        "            output = model(data)         \n",
        "            loss = criterion(output, target)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "        if ( epoch % log_interval == 0 ):\n",
        "            print(f'\\n Epoch {epoch} \\t Training Loss: {train_loss / len(train_dl)} \\t Validation Loss: {valid_loss / len(val_dl)} \\n')\n",
        "\n",
        "        if best_loss > (valid_loss / len(val_dl)):\n",
        "            print(f'Validation Loss Decreased({best_loss:.6f}--->{(valid_loss / len(val_dl)):.6f}) \\t Saving The Model')\n",
        "            best_loss = (valid_loss / len(val_dl))\n",
        "            torch.save(model.state_dict(), 'lstm_saved_model.pth')\n",
        "\n",
        "    return best_loss\n",
        "\n",
        "\n",
        "def smape(a, f):\n",
        "    return 1/len(a) * np.sum(2 * np.abs(f-a) / (np.abs(a) + np.abs(f))*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "im6B6rzG4ClH"
      },
      "outputs": [],
      "source": [
        "\n",
        "def objective(trial):\n",
        "\n",
        "    cfg = { \n",
        "            # 'device' : \"cuda\" if torch.cuda.is_available() else \"cpu\", # 파라미터라고 볼 수 없음\n",
        "            'batch_size' : trial.suggest_categorical('batch_size',[64, 128, 256, 512]), # [64, 128, 256]\n",
        "            # 'num_epochs' : trial.suggest_int('num_epochs', 10, 100, 10), #1000, 1600, 100), # 충분히 학습되는 것이 좋으므로 파라미터라고 볼 수 없음\n",
        "            'learning_rate' : trial.suggest_loguniform('learning_rate', 1e-3, 1e-1), #trial.suggest_loguniform('learning_rate', 1e-2, 1e-1), # learning rate을 0.01-0.1까지 로그 uniform 분포로 사용          \n",
        "            # 'momentum': trial.suggest_uniform('momentum', 0.4, 0.99), # optimizer에서 사용하는 옵션이지만, 코드에서는 사용하지 않음\n",
        "            # 'optimizer': trial.suggest_categorical('optimizer',[optim.SGD, optim.Adam]), # trial.suggest_categorical('optimizer',[optim.SGD, optim.Adam]),\n",
        "            # 'activation': trial.suggest_categorical('activation',[ torch.nn.relu6, torch.nn.relu ]), # 사용되지 않은 parameter\n",
        "            'hidden_size': trial.suggest_categorical('hidden_size',[16, 32, 64, 128, 256, 512, 1024]),\n",
        "            'num_layers': trial.suggest_int('num_layers', 1, 5, 1),       \n",
        "            # 'num_classes': trial.suggest_int('num_classes', 1, 1), # 실수를 예측하므로 고정된 값으로 사용\n",
        "        }\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    lookback_length = 60\n",
        "    forecast_length = max_prediction_length\n",
        "    log_interval = 5\n",
        "    num_classes = 1 # parameter에서 빼서 상수로 설정\n",
        "    num_epochs = 10 # parameter에서 빼서 상수로 설정\n",
        "    x, y = sliding_windows(training_data, lookback_length, forecast_length)\n",
        "\n",
        "    train_dl, val_dl, input_size = get_data_loader(x, y[:, 0, :],  cfg['batch_size'])\n",
        "    \n",
        "    model = LSTM(\n",
        "        num_classes = num_classes, \n",
        "        input_size = input_size, \n",
        "        hidden_size = cfg['hidden_size'], \n",
        "        num_layers = cfg['num_layers']\n",
        "    )\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "        \n",
        "    optimizer = optim.Adam(model.parameters(), lr=cfg['learning_rate'])\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    best_loss = train(log_interval, model, train_dl, val_dl, optimizer, criterion, num_epochs)\n",
        "\n",
        "    # print('best loss for the trial = ', best_loss)\n",
        "    predict_data = []\n",
        "    actual_data = []\n",
        "    # 여기서 x는 (sample, lookback_length, 1)의 크기를 지님. 따라서, 제일 앞의 시점을 제거하려면, x[:, -1, :]이 되어야 함\n",
        "    x_pred = x  # Inference에 사용할 lookback data를 x_pred로 지정. 앞으로 x_pred를 하나씩 옮겨 가면서 inference를 할 예정\n",
        "   \n",
        "    # print('-----------------------y shape before loop = ', y.shape)\n",
        "    for j, i in enumerate(range(max_prediction_length - 1)):\n",
        "\n",
        "        # feed the last forecast back to the model as an input\n",
        "        # print(f'j = {j}')\n",
        "        # print(f'y shape = {y.shape}')\n",
        "        # print(f'Before update data = {x_pred.shape} & y_pred = {y_pred.shape}, expand_dim shape = {np.expand_dims(y[:, j, :], 1).shape}')\n",
        "        x_pred = np.append(x_pred[:, 1:, :], np.expand_dims(y[:, j, :], 1), axis=1)\n",
        "        # print(f'After update data = {x_pred.shape}')\n",
        "        xt_pred = torch.Tensor(x_pred)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            xt_pred = xt_pred.cuda()\n",
        "        # generate the next forecast\n",
        "        yt_pred = model(xt_pred)\n",
        "\n",
        "        # print(f'model result yt_pred = {yt_pred.shape}')\n",
        "        # tensor to array\n",
        "        # x_pred = xt_pred.cpu().detach().numpy()\n",
        "        y_pred = yt_pred.cpu().detach().numpy()\n",
        "\n",
        "        # save the forecast\n",
        "        predict_data.append(y_pred)\n",
        "        # save actual data\n",
        "        actual_data.append(y[:, j, :])\n",
        "\n",
        "    # print(f'After loop predict_data = {len(predict_data)} & predict_data = {len(predict_data)}')\n",
        "    # transform the forecasts back to the original scale\n",
        "    predict_data = np.array(predict_data).reshape(-1, 1)\n",
        "    # predict_data = scaler.inverse_transform(predict_data) # actual_data는 scale되어 있는 데이터임\n",
        "    actual_data = np.array(actual_data).reshape(-1, 1)\n",
        "    \n",
        "    # print(f'predict_data = {predict_data[:3]}, actual data = {actual_data[:3]}')\n",
        "    # print(f'actual size = {actual.shape}, predict = {predict_data.shape}')\n",
        "    SMAPE = smape(actual_data, predict_data)\n",
        "    print(f' \\nSMAPE : {SMAPE}')\n",
        "\n",
        "\n",
        "    return SMAPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDfe0XmG4ChP",
        "outputId": "0934ffae-e972-49be-d8fe-fbfcd9b842d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:51:15,144]\u001b[0m A new study created in memory with name: no-name-11b4f8a9-f604-4509-b41c-3e1ac90fccad\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 0 \t Training Loss: 38.54040144383907 \t Validation Loss: 62.71350860595703 \n",
            "\n",
            "Validation Loss Decreased(inf--->62.713509) \t Saving The Model\n",
            "Validation Loss Decreased(62.713509--->19.083183) \t Saving The Model\n",
            "Validation Loss Decreased(19.083183--->9.727250) \t Saving The Model\n",
            "Validation Loss Decreased(9.727250--->6.433501) \t Saving The Model\n",
            "Validation Loss Decreased(6.433501--->2.297514) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 4.421632528305054 \t Validation Loss: 6.299924850463867 \n",
            "\n",
            "Validation Loss Decreased(2.297514--->0.214509) \t Saving The Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:51:17,432]\u001b[0m Trial 0 finished with value: 165.4524595857317 and parameters: {'batch_size': 512, 'learning_rate': 0.03697182649812958, 'hidden_size': 256, 'num_layers': 4}. Best is trial 0 with value: 165.4524595857317.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "SMAPE : 165.4524595857317\n",
            "\n",
            " Epoch 0 \t Training Loss: 0.06874793364355962 \t Validation Loss: 0.03677862882614136 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.036779) \t Saving The Model\n",
            "Validation Loss Decreased(0.036779--->0.031350) \t Saving The Model\n",
            "Validation Loss Decreased(0.031350--->0.022192) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.025320327530304592 \t Validation Loss: 0.02643493562936783 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:51:18,888]\u001b[0m Trial 1 finished with value: 37.75123570296953 and parameters: {'batch_size': 128, 'learning_rate': 0.0027876331160936138, 'hidden_size': 64, 'num_layers': 5}. Best is trial 1 with value: 37.75123570296953.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "SMAPE : 37.75123570296953\n",
            "\n",
            " Epoch 0 \t Training Loss: 0.09101474409302075 \t Validation Loss: 0.06913561373949051 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.069136) \t Saving The Model\n",
            "Validation Loss Decreased(0.069136--->0.029775) \t Saving The Model\n",
            "Validation Loss Decreased(0.029775--->0.020218) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.02410988664875428 \t Validation Loss: 0.02361592184752226 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:51:19,852]\u001b[0m Trial 2 finished with value: 36.54954318958648 and parameters: {'batch_size': 128, 'learning_rate': 0.0010569506989620532, 'hidden_size': 64, 'num_layers': 3}. Best is trial 2 with value: 36.54954318958648.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "SMAPE : 36.54954318958648\n",
            "\n",
            " Epoch 0 \t Training Loss: 0.14613821357488632 \t Validation Loss: 0.06972413510084152 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.069724) \t Saving The Model\n",
            "Validation Loss Decreased(0.069724--->0.032657) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.05438431724905968 \t Validation Loss: 0.05057688429951668 \n",
            "\n",
            "Validation Loss Decreased(0.032657--->0.022449) \t Saving The Model\n",
            "Validation Loss Decreased(0.022449--->0.021031) \t Saving The Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:51:22,074]\u001b[0m Trial 3 finished with value: 40.54307315274127 and parameters: {'batch_size': 512, 'learning_rate': 0.001431752879189279, 'hidden_size': 256, 'num_layers': 4}. Best is trial 2 with value: 36.54954318958648.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "SMAPE : 40.54307315274127\n",
            "\n",
            " Epoch 0 \t Training Loss: 0.08032984286546707 \t Validation Loss: 0.06726957112550735 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.067270) \t Saving The Model\n",
            "Validation Loss Decreased(0.067270--->0.043475) \t Saving The Model\n",
            "Validation Loss Decreased(0.043475--->0.026469) \t Saving The Model\n",
            "Validation Loss Decreased(0.026469--->0.018428) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.02699997089803219 \t Validation Loss: 0.021634314209222794 \n",
            "\n",
            "Validation Loss Decreased(0.018428--->0.017763) \t Saving The Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:51:22,326]\u001b[0m Trial 4 finished with value: 34.45959896843297 and parameters: {'batch_size': 512, 'learning_rate': 0.003386582056376929, 'hidden_size': 16, 'num_layers': 1}. Best is trial 4 with value: 34.45959896843297.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "SMAPE : 34.45959896843297\n",
            "\n",
            " Epoch 0 \t Training Loss: 0.10390274971723557 \t Validation Loss: 0.07981916517019272 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.079819) \t Saving The Model\n",
            "Validation Loss Decreased(0.079819--->0.036365) \t Saving The Model\n",
            "Validation Loss Decreased(0.036365--->0.028656) \t Saving The Model\n",
            "Validation Loss Decreased(0.028656--->0.019692) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.028166761621832848 \t Validation Loss: 0.028491415083408356 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:51:22,777]\u001b[0m Trial 5 finished with value: 36.76824557386009 and parameters: {'batch_size': 512, 'learning_rate': 0.004421061968362, 'hidden_size': 32, 'num_layers': 3}. Best is trial 4 with value: 34.45959896843297.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "SMAPE : 36.76824557386009\n",
            "\n",
            " Epoch 0 \t Training Loss: 2.3710844665765762 \t Validation Loss: 8.121674537658691 \n",
            "\n",
            "Validation Loss Decreased(inf--->8.121675) \t Saving The Model\n",
            "Validation Loss Decreased(8.121675--->1.584324) \t Saving The Model\n",
            "Validation Loss Decreased(1.584324--->0.379665) \t Saving The Model\n",
            "Validation Loss Decreased(0.379665--->0.216860) \t Saving The Model\n",
            "Validation Loss Decreased(0.216860--->0.076712) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.0664620619888107 \t Validation Loss: 0.029015118877093 \n",
            "\n",
            "Validation Loss Decreased(0.076712--->0.029015) \t Saving The Model\n",
            "Validation Loss Decreased(0.029015--->0.028918) \t Saving The Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:51:24,458]\u001b[0m Trial 6 finished with value: 41.20795265468448 and parameters: {'batch_size': 64, 'learning_rate': 0.030366119775592323, 'hidden_size': 128, 'num_layers': 3}. Best is trial 4 with value: 34.45959896843297.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "SMAPE : 41.20795265468448\n",
            "\n",
            " Epoch 0 \t Training Loss: 0.15845711529254913 \t Validation Loss: 0.14544625580310822 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.145446) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 1.0381923913955688 \t Validation Loss: 1.025760293006897 \n",
            "\n",
            "Validation Loss Decreased(0.145446--->0.094832) \t Saving The Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:51:55,316]\u001b[0m Trial 7 finished with value: 60.74556374657827 and parameters: {'batch_size': 512, 'learning_rate': 0.0027364204936433855, 'hidden_size': 1024, 'num_layers': 5}. Best is trial 4 with value: 34.45959896843297.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "SMAPE : 60.74556374657827\n",
            "\n",
            " Epoch 0 \t Training Loss: 33.574381460125245 \t Validation Loss: 0.09828086445728938 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.098281) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 1.3084408051023881 \t Validation Loss: 0.07508139312267303 \n",
            "\n",
            "Validation Loss Decreased(0.098281--->0.075081) \t Saving The Model\n",
            "Validation Loss Decreased(0.075081--->0.032234) \t Saving The Model\n",
            "Validation Loss Decreased(0.032234--->0.018031) \t Saving The Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:52:00,617]\u001b[0m Trial 8 finished with value: 37.75398109586918 and parameters: {'batch_size': 64, 'learning_rate': 0.019745363418741713, 'hidden_size': 1024, 'num_layers': 1}. Best is trial 4 with value: 34.45959896843297.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "SMAPE : 37.75398109586918\n",
            "\n",
            " Epoch 0 \t Training Loss: 85.3881033907334 \t Validation Loss: 117.74768829345703 \n",
            "\n",
            "Validation Loss Decreased(inf--->117.747688) \t Saving The Model\n",
            "Validation Loss Decreased(117.747688--->71.388397) \t Saving The Model\n",
            "Validation Loss Decreased(71.388397--->25.777920) \t Saving The Model\n",
            "Validation Loss Decreased(25.777920--->4.283720) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 12.17510441939036 \t Validation Loss: 9.680432319641113 \n",
            "\n",
            "Validation Loss Decreased(4.283720--->2.934011) \t Saving The Model\n",
            "Validation Loss Decreased(2.934011--->2.419530) \t Saving The Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:52:02,841]\u001b[0m Trial 9 finished with value: 124.2313030632016 and parameters: {'batch_size': 256, 'learning_rate': 0.05647107544166023, 'hidden_size': 256, 'num_layers': 4}. Best is trial 4 with value: 34.45959896843297.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "SMAPE : 124.2313030632016\n",
            "\n",
            " Epoch 0 \t Training Loss: 0.04673976947863897 \t Validation Loss: 0.018040426075458527 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.018040) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.02230413258075714 \t Validation Loss: 0.02019641548395157 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:52:03,167]\u001b[0m Trial 10 finished with value: 31.322276427053467 and parameters: {'batch_size': 256, 'learning_rate': 0.009099859445297407, 'hidden_size': 16, 'num_layers': 1}. Best is trial 10 with value: 31.322276427053467.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss Decreased(0.018040--->0.017440) \t Saving The Model\n",
            "Validation Loss Decreased(0.017440--->0.016773) \t Saving The Model\n",
            "Validation Loss Decreased(0.016773--->0.016658) \t Saving The Model\n",
            " \n",
            "SMAPE : 31.322276427053467\n",
            "\n",
            " Epoch 0 \t Training Loss: 0.04929540306329727 \t Validation Loss: 0.019696371629834175 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.019696) \t Saving The Model\n",
            "Validation Loss Decreased(0.019696--->0.017819) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.023190120855967205 \t Validation Loss: 0.02193985879421234 \n",
            "\n",
            "Validation Loss Decreased(0.017819--->0.017009) \t Saving The Model\n",
            "Validation Loss Decreased(0.017009--->0.016720) \t Saving The Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:52:03,513]\u001b[0m Trial 11 finished with value: 32.02482404839465 and parameters: {'batch_size': 256, 'learning_rate': 0.00818123148211729, 'hidden_size': 16, 'num_layers': 1}. Best is trial 10 with value: 31.322276427053467.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "SMAPE : 32.02482404839465\n",
            "\n",
            " Epoch 0 \t Training Loss: 0.049719287703434624 \t Validation Loss: 0.0202935840934515 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.020294) \t Saving The Model\n",
            "Validation Loss Decreased(0.020294--->0.020231) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.025171678513288498 \t Validation Loss: 0.022067168727517128 \n",
            "\n",
            "Validation Loss Decreased(0.020231--->0.019905) \t Saving The Model\n",
            "Validation Loss Decreased(0.019905--->0.019368) \t Saving The Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:52:04,001]\u001b[0m Trial 12 finished with value: 36.48306965390798 and parameters: {'batch_size': 256, 'learning_rate': 0.01018980483094186, 'hidden_size': 16, 'num_layers': 2}. Best is trial 10 with value: 31.322276427053467.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "SMAPE : 36.48306965390798\n",
            "\n",
            " Epoch 0 \t Training Loss: 9.424576510985693 \t Validation Loss: 3.419151782989502 \n",
            "\n",
            "Validation Loss Decreased(inf--->3.419152) \t Saving The Model\n",
            "Validation Loss Decreased(3.419152--->0.586469) \t Saving The Model\n",
            "Validation Loss Decreased(0.586469--->0.049201) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.17060757180054983 \t Validation Loss: 0.05042864382266998 \n",
            "\n",
            "Validation Loss Decreased(0.049201--->0.029211) \t Saving The Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:52:07,330]\u001b[0m Trial 13 finished with value: 46.268156173121504 and parameters: {'batch_size': 256, 'learning_rate': 0.00905892940657813, 'hidden_size': 512, 'num_layers': 2}. Best is trial 10 with value: 31.322276427053467.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "SMAPE : 46.268156173121504\n",
            "\n",
            " Epoch 0 \t Training Loss: 0.04820763195554415 \t Validation Loss: 0.018762031570076942 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.018762) \t Saving The Model\n",
            "Validation Loss Decreased(0.018762--->0.018102) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.022828880697488785 \t Validation Loss: 0.02118365466594696 \n",
            "\n",
            "Validation Loss Decreased(0.018102--->0.017962) \t Saving The Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:52:07,630]\u001b[0m Trial 14 finished with value: 31.70815092632409 and parameters: {'batch_size': 256, 'learning_rate': 0.008562309249864718, 'hidden_size': 16, 'num_layers': 1}. Best is trial 10 with value: 31.322276427053467.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss Decreased(0.017962--->0.016880) \t Saving The Model\n",
            "Validation Loss Decreased(0.016880--->0.016675) \t Saving The Model\n",
            " \n",
            "SMAPE : 31.70815092632409\n",
            "\n",
            " Epoch 0 \t Training Loss: 0.22494391724467278 \t Validation Loss: 0.045173294842243195 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.045173) \t Saving The Model\n",
            "Validation Loss Decreased(0.045173--->0.028576) \t Saving The Model\n",
            "Validation Loss Decreased(0.028576--->0.027373) \t Saving The Model\n",
            "Validation Loss Decreased(0.027373--->0.023440) \t Saving The Model\n",
            "Validation Loss Decreased(0.023440--->0.019593) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.028810201833645504 \t Validation Loss: 0.02477121911942959 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:52:08,080]\u001b[0m Trial 15 finished with value: 36.517858221211064 and parameters: {'batch_size': 256, 'learning_rate': 0.0975881353471323, 'hidden_size': 16, 'num_layers': 2}. Best is trial 10 with value: 31.322276427053467.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss Decreased(0.019593--->0.019350) \t Saving The Model\n",
            " \n",
            "SMAPE : 36.517858221211064\n",
            "\n",
            " Epoch 0 \t Training Loss: 0.036802864323059716 \t Validation Loss: 0.04947724565863609 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.049477) \t Saving The Model\n",
            "Validation Loss Decreased(0.049477--->0.020066) \t Saving The Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:52:08,416]\u001b[0m Trial 16 finished with value: 32.20239499299219 and parameters: {'batch_size': 256, 'learning_rate': 0.01502702017107707, 'hidden_size': 16, 'num_layers': 1}. Best is trial 10 with value: 31.322276427053467.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss Decreased(0.020066--->0.019978) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.020365990698337555 \t Validation Loss: 0.017180688679218292 \n",
            "\n",
            "Validation Loss Decreased(0.019978--->0.017181) \t Saving The Model\n",
            "Validation Loss Decreased(0.017181--->0.017103) \t Saving The Model\n",
            " \n",
            "SMAPE : 32.20239499299219\n",
            "\n",
            " Epoch 0 \t Training Loss: 0.08422850196560223 \t Validation Loss: 0.10852910578250885 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.108529) \t Saving The Model\n",
            "Validation Loss Decreased(0.108529--->0.073296) \t Saving The Model\n",
            "Validation Loss Decreased(0.073296--->0.061277) \t Saving The Model\n",
            "Validation Loss Decreased(0.061277--->0.036128) \t Saving The Model\n",
            "Validation Loss Decreased(0.036128--->0.023168) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.025049264853199322 \t Validation Loss: 0.02301870472729206 \n",
            "\n",
            "Validation Loss Decreased(0.023168--->0.023019) \t Saving The Model\n",
            "Validation Loss Decreased(0.023019--->0.021892) \t Saving The Model\n",
            "Validation Loss Decreased(0.021892--->0.020573) \t Saving The Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:52:09,009]\u001b[0m Trial 17 finished with value: 35.65748634671147 and parameters: {'batch_size': 256, 'learning_rate': 0.005313187290836165, 'hidden_size': 128, 'num_layers': 2}. Best is trial 10 with value: 31.322276427053467.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "SMAPE : 35.65748634671147\n",
            "\n",
            " Epoch 0 \t Training Loss: 0.0845626915494601 \t Validation Loss: 0.024731244891881943 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.024731) \t Saving The Model\n",
            "Validation Loss Decreased(0.024731--->0.019213) \t Saving The Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:52:09,390]\u001b[0m Trial 18 finished with value: 30.53173139099194 and parameters: {'batch_size': 256, 'learning_rate': 0.015507603161339997, 'hidden_size': 32, 'num_layers': 1}. Best is trial 18 with value: 30.53173139099194.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss Decreased(0.019213--->0.017032) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.02199672597150008 \t Validation Loss: 0.016890130937099457 \n",
            "\n",
            "Validation Loss Decreased(0.017032--->0.016890) \t Saving The Model\n",
            "Validation Loss Decreased(0.016890--->0.016414) \t Saving The Model\n",
            " \n",
            "SMAPE : 30.53173139099194\n",
            "\n",
            " Epoch 0 \t Training Loss: 0.07045551389455795 \t Validation Loss: 0.04768942482769489 \n",
            "\n",
            "Validation Loss Decreased(inf--->0.047689) \t Saving The Model\n",
            "Validation Loss Decreased(0.047689--->0.030311) \t Saving The Model\n",
            "Validation Loss Decreased(0.030311--->0.021099) \t Saving The Model\n",
            "\n",
            " Epoch 5 \t Training Loss: 0.02554055241247018 \t Validation Loss: 0.026631860062479973 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-06-16 22:52:10,144]\u001b[0m Trial 19 finished with value: 35.953759023534275 and parameters: {'batch_size': 128, 'learning_rate': 0.015498810013577778, 'hidden_size': 32, 'num_layers': 2}. Best is trial 18 with value: 30.53173139099194.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "SMAPE : 35.953759023534275\n"
          ]
        }
      ],
      "source": [
        "sampler = optuna.samplers.TPESampler()\n",
        "#   sampler = optuna.samplers.SkoptSampler()\n",
        "\n",
        "# model.load_state_dict(torch.load('lstm_saved_model.pth'))\n",
        "    \n",
        "study = optuna.create_study(sampler=sampler, direction='minimize')\n",
        "study.optimize(objective, n_trials= 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uZ0lcfrb4CdY"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(929, 1, 1)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.expand_dims(y[:, 9, :], 1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "LSTM-pytorch_optuna_05.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "3adb55b36cf11984244f732b8044a5f95e16798e2d742560837f6dd41133e800"
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit ('image_crawler')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
