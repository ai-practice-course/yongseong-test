{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occupied-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable  # http://taewan.kim/trans/pytorch/tutorial/blits/02_autograd/\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pickle\n",
    "import optuna\n",
    "import torch.optim as optim \n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wireless-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/crypto_currency.pickle', 'rb') as f:  # 'rb'는 binary로 읽겠다는 의미 (문자열이 아닌 객체를 읽어보겠다는 뜻)\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "posted-harmony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candle_date_time_kst</th>\n",
       "      <th>trade_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-09-25T09:00:00</td>\n",
       "      <td>325000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-09-26T09:00:00</td>\n",
       "      <td>321500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-09-27T09:00:00</td>\n",
       "      <td>342500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-09-28T09:00:00</td>\n",
       "      <td>332500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-09-29T09:00:00</td>\n",
       "      <td>327500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   candle_date_time_kst  trade_price\n",
       "17  2017-09-25T09:00:00     325000.0\n",
       "16  2017-09-26T09:00:00     321500.0\n",
       "15  2017-09-27T09:00:00     342500.0\n",
       "14  2017-09-28T09:00:00     332500.0\n",
       "13  2017-09-29T09:00:00     327500.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bch = data['KRW-ETH'][['candle_date_time_kst', 'trade_price']]\n",
    "bch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "liquid-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "bch.set_index('candle_date_time_kst', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "polished-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(data) - seq_length - 1):  # i는 총 699개임, seq_length는 20개, i는 예측 대상일이므로 1개가됨. \n",
    "        _x = data[i: (i + seq_length)]  # _x에는 길이가 20인 vector가 들어감\n",
    "        _y = data[i + seq_length]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "applied-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "training_data = sc.fit_transform(bch[['trade_price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "combined-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = sliding_windows(training_data, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "configured-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM, self).__init__()  # 객체화 과정에서 가장 먼저 사용하는 함수(initialize), 메모리에 올릴 때 이 작업을 함\n",
    "        self.num_classes = num_classes  # 함수의 인자들을 class가 인식할 수 있도록 self 키워드를 붙여서 다시 저장\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, \n",
    "                            num_layers = num_layers, batch_first = True)  # lstm이라는 layer가 괄호 속 인자들을 가지고 있는 pytorch의 LSTM 모듈을 가짐.\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)  # fully connected layer, num_classes는 1개\n",
    "        # input_size는 1개가 20번씩 들어감 (20개의 일자), hidden_size는 cell state와 hidden state의 크기로 hyper param임 (보통 4의 배수를 사용)\n",
    "        # num_layers는 layer들을 stacking하는 개수를 의미 \n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))  # 첫 단계의 값이 없으므로 zero 행렬 이용 0으로 설정\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        # propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "#         h_out = h_out.view(-1, self.hidden_size)  # output은 매 단계마다 나오며, 그 중 맨 마지막 값만 출력\n",
    "        h_out = h_out[-1, :, :].view(-1, self.hidden_size)\n",
    "#         print(f'hidden = {self.hidden_size}')\n",
    "#         print(f'seq_len = {seq_length}')\n",
    "#         print(f'h shape = {h_out.shape}')\n",
    "        \n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "collected-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "tropical-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trial): \n",
    "  cfg = {'train_batch_size' : trial.suggest_categorical('train_batch_size',[16, 32, 64, 128, 256, 512]),\n",
    "         'test_batch_size' : trial.suggest_categorical('test_batch_size',[16, 32, 64, 128, 256, 512]), \n",
    "         'num_epochs' : trial.suggest_int('n_epochs', 5, 50, 1), \n",
    "         'seed' : 0, \n",
    "         'save_model' : False, \n",
    "         'lr' : trial.suggest_loguniform('lr', 1e-3, 1e-2), \n",
    "         'seq_length' : trial.suggest_int('seq_length', 7, 30, 1),\n",
    "         'num_layers' : trial.suggest_int('num_layers', 1, 3, 1),\n",
    "         'hidden_size' : trial.suggest_categorical('hidden_size',[16, 32, 64, 128, 256, 512]),\n",
    "         'input_size' : 1,\n",
    "         'num_classes' : 1,\n",
    "         'optimizer': trial.suggest_categorical('optimizer',[torch.optim.Adam])} \n",
    "         \n",
    "  torch.manual_seed(cfg['seed']) \n",
    "\n",
    "  train_ds = TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
    "  train_dl = DataLoader(train_ds, batch_size=cfg['train_batch_size'])\n",
    "\n",
    "  test_ds = TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test))\n",
    "  test_dl = DataLoader(test_ds, batch_size=cfg['test_batch_size'])\n",
    "\n",
    "  model = LSTM(num_classes=cfg['num_classes'], \n",
    "               input_size =cfg['input_size'], \n",
    "               hidden_size=cfg['hidden_size'], \n",
    "               num_layers=cfg['num_layers'], \n",
    "               seq_length=cfg['seq_length']\n",
    "  )\n",
    "  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr']) \n",
    "  criterion = torch.nn.MSELoss()\n",
    "\n",
    "  for epoch in range(1, cfg['num_epochs'] + 1):\n",
    "    for xb, yb in train_dl:\n",
    "        outputs = model(xb)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, loss: {loss.item()}')    \n",
    "    \n",
    "  if cfg['save_model']: \n",
    "    torch.save(model.state_dict(), \"lstm_optuna.pt\") \n",
    "\n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "broken-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "portable-jason",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 22:24:04,310]\u001b[0m A new study created in memory with name: no-name-8e3947d6-dd56-42d9-8ca6-da213b93d23f\u001b[0m\n",
      "/home/kyle/.pyenv/versions/image_crawler/lib/python3.8/site-packages/optuna/distributions.py:427: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "\u001b[32m[I 2022-05-22 22:24:06,603]\u001b[0m Trial 0 finished with value: 0.0619717538356781 and parameters: {'train_batch_size': 64, 'test_batch_size': 512, 'n_epochs': 11, 'lr': 0.0071683185174127315, 'seq_length': 26, 'num_layers': 1, 'hidden_size': 64, 'optimizer': <class 'torch.optim.adam.Adam'>}. Best is trial 0 with value: 0.0619717538356781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 0.08626867085695267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/.pyenv/versions/image_crawler/lib/python3.8/site-packages/optuna/distributions.py:427: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 0.03725602850317955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 22:24:09,781]\u001b[0m Trial 1 finished with value: 0.005028170067816973 and parameters: {'train_batch_size': 128, 'test_batch_size': 512, 'n_epochs': 17, 'lr': 0.009853268519878123, 'seq_length': 8, 'num_layers': 1, 'hidden_size': 64, 'optimizer': <class 'torch.optim.adam.Adam'>}. Best is trial 0 with value: 0.0619717538356781.\u001b[0m\n",
      "/home/kyle/.pyenv/versions/image_crawler/lib/python3.8/site-packages/optuna/distributions.py:427: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "\u001b[32m[I 2022-05-22 22:24:14,088]\u001b[0m Trial 2 finished with value: 0.06282902508974075 and parameters: {'train_batch_size': 16, 'test_batch_size': 32, 'n_epochs': 9, 'lr': 0.0010933762086160212, 'seq_length': 18, 'num_layers': 1, 'hidden_size': 16, 'optimizer': <class 'torch.optim.adam.Adam'>}. Best is trial 2 with value: 0.06282902508974075.\u001b[0m\n",
      "/home/kyle/.pyenv/versions/image_crawler/lib/python3.8/site-packages/optuna/distributions.py:427: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 0.646763801574707\n",
      "Epoch: 20, loss: 0.058330684900283813\n",
      "Epoch: 30, loss: 0.043867215514183044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 22:25:55,373]\u001b[0m Trial 3 finished with value: 0.05614763870835304 and parameters: {'train_batch_size': 128, 'test_batch_size': 32, 'n_epochs': 38, 'lr': 0.0026867991671455853, 'seq_length': 9, 'num_layers': 3, 'hidden_size': 256, 'optimizer': <class 'torch.optim.adam.Adam'>}. Best is trial 2 with value: 0.06282902508974075.\u001b[0m\n",
      "/home/kyle/.pyenv/versions/image_crawler/lib/python3.8/site-packages/optuna/distributions.py:427: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 0.051313694566488266\n",
      "Epoch: 20, loss: 0.014670992270112038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 22:27:01,646]\u001b[0m Trial 4 finished with value: 0.047387246042490005 and parameters: {'train_batch_size': 128, 'test_batch_size': 32, 'n_epochs': 27, 'lr': 0.004685448735516767, 'seq_length': 25, 'num_layers': 3, 'hidden_size': 256, 'optimizer': <class 'torch.optim.adam.Adam'>}. Best is trial 2 with value: 0.06282902508974075.\u001b[0m\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/gdrive/My Drive/Colab_Data/studies/mnist_optuna.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-464e78456039>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/gdrive/My Drive/Colab_Data/studies/mnist_optuna.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/image_crawler/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/Colab_Data/studies/mnist_optuna.pkl'"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler() \n",
    "\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize') \n",
    "study.optimize(train_model, n_trials=5) \n",
    "joblib.dump(study, '/content/gdrive/My Drive/Colab_Data/studies/mnist_optuna.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-forestry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImageProcesss",
   "language": "python",
   "name": "image_crawler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
